{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BICING_URL = \"http://wservice.viabicing.cat/v2/stations\"\n",
    "OUTPUT_PATH = \"output\"\n",
    "STATIONS_FILE = \"output/stations.csv\"\n",
    "SECONDS_UPDATE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchBicingData(url = BICING_URL):\n",
    "    r = requests.get(url)\n",
    "    bicingJson = r.json()\n",
    "    updateTime = bicingJson[\"updateTime\"]\n",
    "    bicingDf = pd.DataFrame.from_dict(bicingJson[\"stations\"])\n",
    "    bicingDf[\"nearbyStations\"] = bicingDf[\"nearbyStations\"].apply(lambda x: re.sub(\", \", \" - \", x))\n",
    "    bicingDf[\"updateTime\"] = ConvertTimestampToUtcString(updateTime)\n",
    "    return(bicingDf)\n",
    "\n",
    "def ConvertTimestampToUtcString(timestamp):\n",
    "    timestampLocal = datetime.fromtimestamp(timestamp)\n",
    "    timestampUtc = timestampLocal.astimezone(timezone(\"UTC\"))\n",
    "    timestampString = timestampUtc.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")\n",
    "    return(timestampString)\n",
    "\n",
    "def CreateStationsFile(file = STATIONS_FILE):\n",
    "    fieldsList = [\"internalId\", \"id\", \"type\", \"streetName\", \"streetNumber\", \"latitude\",\n",
    "                   \"longitude\", \"altitude\"]\n",
    "    with open(file, 'w', newline = '') as myfile:\n",
    "        wr = csv.writer(myfile, delimiter = \";\")\n",
    "        wr.writerow(fieldsList)\n",
    "#    print(\"Stations file created.\")\n",
    "\n",
    "def CreateDataFile(internalId, outputPath = OUTPUT_PATH):\n",
    "    internalId = int(internalId)\n",
    "    fieldsList = [\"updateTime\", \"status\", \"bikes\", \"slots\", \"nearbyStations\"]\n",
    "    file = outputPath + \"/\" + str(internalId).zfill(5) + \".csv\"\n",
    "    with open(file, 'w', newline = '') as myfile:\n",
    "        wr = csv.writer(myfile, delimiter = \";\")\n",
    "        wr.writerow(fieldsList)\n",
    "#    print(\"Data file for station \" + str(internalId) + \" created.\")\n",
    "\n",
    "def ReadStationsFile(file = STATIONS_FILE):\n",
    "    converters = {\"id\": str, \"type\": str, \"streetName\": str, \"streetNumber\": str,\n",
    "                  \"latitude\": str, \"longitude\": str, \"altitude\": str}\n",
    "    if os.path.isfile(file) == False:\n",
    "        CreateStationsFile(file)\n",
    "    stations = pd.read_csv(file, delimiter = \";\", encoding = \"latin-1\", converters = converters)\n",
    "    return(stations)\n",
    "\n",
    "def UpdateStationsFile(internalId, row, file = STATIONS_FILE):\n",
    "    internalId = int(internalId)\n",
    "    values_list = [internalId, row[\"id\"], row[\"type\"], row[\"streetName\"], row[\"streetNumber\"], row[\"latitude\"],\n",
    "                   row[\"longitude\"], row[\"altitude\"]]\n",
    "    with open(file, 'a', newline = '') as myfile:\n",
    "        wr = csv.writer(myfile, delimiter = \";\", quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(values_list)\n",
    "#    print(\"Stations file updated with station \" + str(internalId) + \".\")\n",
    "\n",
    "def UpdateDataFile(internalId, row, outputPath = OUTPUT_PATH):\n",
    "    internalId = int(internalId)\n",
    "    values_list = [row[\"updateTime\"], row[\"status\"], row[\"bikes\"], row[\"slots\"], row[\"nearbyStations\"]]\n",
    "    file = outputPath + \"/\" + str(internalId).zfill(5) + \".csv\"\n",
    "    with open(file, 'a', newline = '') as myfile:\n",
    "        wr = csv.writer(myfile, delimiter = \";\")\n",
    "        wr.writerow(values_list)\n",
    "#    print(\"Data for station \" + str(internalId) + \" updated.\")\n",
    "\n",
    "def SaveBicingData(stationsFile = STATIONS_FILE, outputPath = OUTPUT_PATH):\n",
    "    stations = ReadStationsFile(stationsFile)\n",
    "    bicing = FetchBicingData()\n",
    "    bicingStations = pd.merge(bicing, stations[[\"internalId\", \"id\", \"type\", \"latitude\", \"longitude\", \"altitude\"]],\n",
    "                              on = [\"id\", \"type\", \"latitude\", \"longitude\", \"altitude\"],\n",
    "                              how = \"left\")\n",
    "    if np.all(bicingStations[\"internalId\"].isna()):\n",
    "        nextStation = 1\n",
    "    else:\n",
    "        nextStation = np.nanmax(bicingStations[\"internalId\"]) + 1\n",
    "    for index, row in bicingStations.iterrows():\n",
    "        internalId = row[\"internalId\"]\n",
    "        if np.isnan(internalId):\n",
    "            internalId = nextStation\n",
    "            UpdateStationsFile(internalId, row, stationsFile)\n",
    "            CreateDataFile(internalId, outputPath)\n",
    "            nextStation = nextStation + 1\n",
    "        UpdateDataFile(internalId, row, outputPath)\n",
    "    print(\"Bicing data updated at \" + row[\"updateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    SaveBicingData()\n",
    "    time.sleep(SECONDS_UPDATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
